<problem>
  <p>Which of the following are use cases for Amazon DynamoDB? Choose 3 answers</p>
  <choiceresponse>
    <checkboxgroup>
      <choice correct="False">Storing BLOB data.</choice>
      <choice correct="False">Managing web sessions.</choice>
      <choice correct="True">Storing JSON documents.</choice>
      <choice correct="False">Storing metadata for Amazon S3 objects.</choice>
      <choice correct="True">Running relational joins and complex updates.</choice>
      <choice correct="True">Storing large amounts of infrequently accessed data.</choice>
    </checkboxgroup>
  </choiceresponse>
</problem>
<problem>
  <p>Which of the following statements are true about Amazon Route 53 resource records? Choose 2 answers</p>
  <choiceresponse>
    <checkboxgroup>
      <choice correct="True">An Alias record can map one DNS name to another Amazon Route 53 DNS name.</choice>
      <choice correct="False">A CNAME record can be created for your zone apex.</choice>
      <choice correct="True">An Amazon Route 53 CNAME record can point to any DNS record hosted anywhere.</choice>
      <choice correct="False">TTL can be set for an Alias record in Amazon Route 53.</choice>
      <choice correct="False">An Amazon Route 53 Alias record can point to any DNS record hosted anywhere.</choice>
    </checkboxgroup>
  </choiceresponse>
</problem>
<problem>
  <p>Your company has HQ in Tokyo and branch offices all over the world and is using a logistics software with a multi-regional deployment on AWS in Japan, Europe and US</p>
  <choiceresponse>
    <checkboxgroup>
      <choice correct="True">The logistic software has a 3-tier architecture and currently uses MySQL 5.6 for data persistence. Each region has deployed its own database In the HQ region you run an hourly batch process reading data from every region to compute cross-regional reports that are sent by email to all offices this batch process must be completed as fast as possible to quickly optimize logistics how do you build the database architecture in order to meet the requirements’?  For each regional deployment, use RDS MySQL with a master in the region and a read replica in the HQ region</choice>
      <choice correct="True">The logistic software has a 3-tier architecture and currently uses MySQL 5.6 for data persistence. Each region has deployed its own database In the HQ region you run an hourly batch process reading data from every region to compute cross-regional reports that are sent by email to all offices this batch process must be completed as fast as possible to quickly optimize logistics how do you build the database architecture in order to meet the requirements’?  For each regional deployment, use RDS MySQL with a master in the region and a read replica in the HQ region</choice>
      <choice correct="False">For each regional deployment, use MySQL on EC2 with a master in the region and send hourly EBS snapshots to the HQ region</choice>
      <choice correct="False">For each regional deployment, use RDS MySQL with a master in the region and send hourly RDS snapshots to the HQ region</choice>
      <choice correct="False">For each regional deployment, use MySQL on EC2 with a master in the region and use S3 to copy data files hourly to the HQ region</choice>
      <choice correct="False">Use Direct Connect to connect all regional MySQL deployments to the HQ region and reduce network latency for the batch process</choice>
    </checkboxgroup>
  </choiceresponse>
</problem>
<problem>
  <p>A customer has a 10 GB AWS Direct Connect connection to an AWS region where they have a web application hosted on Amazon Elastic Computer Cloud (EC2). The application has dependencies on an on-premises mainframe database that uses a BASE (Basic Available. Sort stale Eventual consistency) rather than an ACID (Atomicity. Consistency isolation. Durability) consistency model. The application is exhibiting undesirable behavior because the database is not able to handle the volume of writes. How can you reduce the load on your on-premises database resources in the most cost-effective way?</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="True">Use an Amazon Elastic Map Reduce (EMR) S3DistCp as a synchronization mechanism between the onpremises database and a Hadoop cluster on AWS.</choice>
      <choice correct="False">Modify the application to write to an Amazon SQS queue and develop a worker process to flush the queue to the on-premises database.</choice>
      <choice correct="False">Modify the application to use DynamoDB to feed an EMR cluster which uses a map function to write to the on-premises database.</choice>
      <choice correct="False">Provision an RDS read-replica database on AWS to handle the writes and synchronize the two databases using Data Pipeline.</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>A 3-tier e-commerce web application is current deployed on-premises and will be migrated to AWS for greater scalability and elasticity The web server currently shares read-only data using a network distributed file system The app server tier uses a clustering mechanism for discovery and shared session state that depends on IP multicast The database tier uses shared-storage clustering to provide database fall over capability, and uses several read slaves for scaling Data on all servers and the distributed file system directory is backed up weekly to off-site tapes Which AWS storage and database architecture meets the requirements of the application?</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="False">Web servers, store read-only data in S3, and copy from S3 to root volume at boot time App servers snare state using a combination or DynamoDB and IP unicast Database use RDS with multi-AZ deployment and one or more Read Replicas Backup web and app servers backed up weekly via Mils database backed up via DB snapshots.</choice>
      <choice correct="True">Web servers store -read-only data in S3, and copy from S3 to root volume at boot time App servers share state using a combination of DynamoDB and IP unicast Database, use RDS with multi-AZ deployment and one or more read replicas Backup web servers app servers, and database backed up weekly to Glacier using snapshots.</choice>
      <choice correct="False">Web servers store read-only data In S3 and copy from S3 to root volume at boot time App servers share state using a combination of DynamoDB and IP unicast Database use RDS with multi-AZ deployment Backup web and app servers backed up weekly via AM is. database backed up via DB snapshots</choice>
      <choice correct="False">Web servers, store read-only data in an EC2 NFS server, mount to each web server at boot time App servers share state using a combination of DynamoDB and IP multicast Database use RDS with multl-AZ deployment and one or more Read Replicas Backup web and app servers backed up weekly via Mils database backed up via DB snapshots</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>Your customer wishes to deploy an enterprise application to AWS which will consist of several web servers, several application servers and a small (50GB) Oracle database information is stored, both in the database and the file systems of the various servers. The backup system must support database recovery whole server and whole disk restores, and individual file restores with a recovery time of no more than two hours. They have chosen to use RDS Oracle as the database Which backup architecture will meet these requirements?</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="False">Backup RDS using automated daily DB backups Backup the EC2 instances using AMIs and supplement with file-level backup to S3 using traditional enterprise backup software to provide file level restore</choice>
      <choice correct="False">Backup RDS using a Multi-AZ Deployment Backup the EC2 instances using Amis, and supplement by copying file system data to S3 to provide file level restore.</choice>
      <choice correct="True">Backup RDS using automated daily DB backups Backup the EC2 instances using EBS snapshots and supplement with file-level backups to Amazon Glacier using traditional enterprise backup software to provide file level restore</choice>
      <choice correct="False">Backup RDS database to S3 using Oracle RMAN Backup the EC2 instances using Amis, and supplement with EBS snapshots for individual volume restore.</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>Company B is launching a new game app for mobile devices. Users will log into the game using their existing social media account to streamline data capture. Company B would like to directly save player data and scoring information from the mobile app to a DynamoDS table named Score Data When a user saves their game the progress data will be stored to the Game state S3 bucket. what is the best approach for storing data to DynamoDB and S3?</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="True">Use an EC2 Instance that is launched with an EC2 role providing access to the Score Data DynamoDB table and the GameState S3 bucket that communicates with the mobile app via web services.</choice>
      <choice correct="False">Use temporary security credentials that assume a role providing access to the Score Data DynamoDB table and the Game State S3 bucket using web identity federation.</choice>
      <choice correct="False">Use Login with Amazon allowing users to sign in with an Amazon account providing the mobile app with access to the Score Data DynamoDB table and the Game State S3 bucket.</choice>
      <choice correct="False">Use an IAM user with access credentials assigned a role providing access to the Score Data DynamoDB table and the Game State S3 bucket for distribution with the mobile app.</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>A company needs to monitor the read and write IOPs metrics for their AWS MySQL RDS instance and send real-time alerts to their operations team. Which AWS services can accomplish this? Choose 2 answers</p>
  <choiceresponse>
    <checkboxgroup>
      <choice correct="False">Amazon Simple Email Service</choice>
      <choice correct="True">Amazon CloudWatch</choice>
      <choice correct="False">Amazon Simple Queue Service</choice>
      <choice correct="True">Amazon Route 53</choice>
      <choice correct="False">Amazon Simple Notification Service</choice>
    </checkboxgroup>
  </choiceresponse>
</problem>
<problem>
  <p>Which set of Amazon S3 features helps to prevent and recover from accidental data loss?</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="False">Object lifecycle and service access logging</choice>
      <choice correct="True">Object versioning and Multi-factor authentication</choice>
      <choice correct="False">Access controls and server-side encryption</choice>
      <choice correct="False">Website hosting and Amazon S3 policies</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>You are deploying an application to collect votes for a very popular television show. Millions of users will submit votes using mobile devices. The votes must be collected into a durable, scalable, and highly available data store for real-time public tabulation. Which service should you use?</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="True">Amazon DynamoDB</choice>
      <choice correct="False">Amazon Redshift</choice>
      <choice correct="False">Amazon Kinesis</choice>
      <choice correct="False">Amazon Simple Queue Service</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>A customer implemented AWS Storage Gateway with a gateway-cached volume at their main office. An event takes the link between the main and branch office offline. Which methods will enable the branch office to access their data? Choose 3 answers</p>
  <choiceresponse>
    <checkboxgroup>
      <choice correct="True">Use a HTTPS GET to the Amazon S3 bucket where the files are located.</choice>
      <choice correct="False">Restore by implementing a lifecycle policy on the Amazon S3 bucket.</choice>
      <choice correct="False">Make an Amazon Glacier Restore API call to load the files into another Amazon S3 bucket within four to six hours.</choice>
      <choice correct="True">Launch a new AWS Storage Gateway instance AMI in Amazon EC2, and restore from a gateway snapshot.</choice>
      <choice correct="False">Create an Amazon EBS volume from a gateway snapshot, and mount it to an Amazon EC2 instance.</choice>
      <choice correct="True">Launch an AWS Storage Gateway virtual iSCSI device at the branch office, and restore from a gateway snapshot.</choice>
    </checkboxgroup>
  </choiceresponse>
</problem>
<problem>
  <p>What is the minimum time Interval for the data that Amazon CloudWatch receives and aggregates?</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="False">One second</choice>
      <choice correct="False">Five seconds</choice>
      <choice correct="True">One minute</choice>
      <choice correct="False">Three minutes</choice>
      <choice correct="False">Five minutes</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>You are deploying an application to track GPS coordinates of delivery trucks in the United States. Coordinates are transmitted from each delivery truck once every three seconds. You need to design an architecture that will enable real-time processing of these coordinates from multiple consumers. Which service should you use to implement data ingestion?</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="True">Amazon Kinesis</choice>
      <choice correct="False">AWS Data Pipeline</choice>
      <choice correct="False">Amazon AppStream</choice>
      <choice correct="False">Amazon Simple Queue Service</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>Which of the following notification endpoints or clients are supported by Amazon Simple Notification Service? Choose 2 answers</p>
  <choiceresponse>
    <checkboxgroup>
      <choice correct="True">Email</choice>
      <choice correct="False">CloudFront distribution</choice>
      <choice correct="False">File Transfer Protocol</choice>
      <choice correct="True">Short Message Service</choice>
      <choice correct="False">Simple Network Management Protocol</choice>
    </checkboxgroup>
  </choiceresponse>
</problem>
<problem>
  <p>You have an application running on an Amazon Elastic Compute Cloud instance, that uploads 5 GB video objects to Amazon Simple Storage Service (S3). Video uploads are taking longer than expected, resulting in poor application performance. Which method will help improve performance of your application?</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="False">Enable enhanced networking</choice>
      <choice correct="False">Use Amazon S3 multipart upload</choice>
      <choice correct="False">Leveraging Amazon CloudFront, use the HTTP POST method to reduce latency.</choice>
      <choice correct="True">Use Amazon Elastic Block Store Provisioned IOPs and use an Amazon EBS-optimized instance</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>A photo-sharing service stores pictures in Amazon Simple Storage Service (S3) and allows application sign-in using an OpenID Connect-compatible identity provider. Which AWS Security Token Service approach to temporary access should you use for the Amazon S3 operations?</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="False">SAML-based Identity Federation</choice>
      <choice correct="False">Cross-Account Access</choice>
      <choice correct="True">AWS Identity and Access Management roles</choice>
      <choice correct="False">Web Identity Federation</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>You are responsible for a legacy web application whose server environment is approaching end of life You would like to migrate this application to AWS as quickly as possible, since the application environment currently has the following limitations: The VM’s single 10GB VMDK is almost full</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="False">completely underutilizedIt is currently running on a highly customized. Windows VM within a VMware environment:You do not have me installation mediaThis is a mission critical application with an RTO (Recovery Time Objective) of 8 hours. RPO (Recovery PointObjective) of 1 hour. How could you best migrate this application to AWS while meeting your businesscontinuity requirements?</choice>
      <choice correct="True">Use the EC2 VM Import Connector for vCenter to import the VM into EC2.</choice>
      <choice correct="False">Use Import/Export to import the VM as an ESS snapshot and attach to EC2.</choice>
      <choice correct="False">Use S3 to create a backup of the VM and restore the data into EC2.</choice>
      <choice correct="False">Use me ec2-bundle-instance API to Import an Image of the VM into EC2</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>An International company has deployed a multi-tier web application that relies on DynamoDB in a single region For regulatory reasons they need disaster recovery capability In a separate region with a Recovery Time Objective of 2 hours and a Recovery Point Objective of 24 hours They should synchronize their data on a regular basis and be able to provision me web application rapidly using CloudFormation. The objective is to minimize changes to the existing web application, control the throughput of DynamoDB used for the synchronization of data and synchronize only the modified elements. Which design would you choose to meet these requirements?</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="False">Use AWS data Pipeline to schedule a DynamoDB cross region copy once a day. create a Lastupdated’ attribute in your DynamoDB table that would represent the timestamp of the last update and use it as a filter.</choice>
      <choice correct="False">Use EMR and write a custom script to retrieve data from DynamoDB in the current region using a SCAN operation and push it to QynamoDB in the second region.</choice>
      <choice correct="True">Use AWS data Pipeline to schedule an export of the DynamoDB table to S3 in the current region once a day then schedule another task immediately after it that will import data from S3 to DynamoDB in the other region.</choice>
      <choice correct="False">Send also each Ante into an SQS queue in me second region; use an auto-scaiing group behind the SQS queue to replay the write in the second region.</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>A customer wants to track access to their Amazon Simple Storage Service (S3) buckets and also use this information for their internal security and access audits. Which of the following will meet the Customer requirement?</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="False">Enable AWS CloudTrail to audit all Amazon S3 bucket access.</choice>
      <choice correct="True">Enable server access logging for all required Amazon S3 buckets.</choice>
      <choice correct="False">Enable the Requester Pays option to track access via AWS Billing</choice>
      <choice correct="False">Enable Amazon S3 event notifications for Put and Post.</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>Your company currently has a 2-tier web application running in an on-premises data center. You have experienced several infrastructure failures in the past two months resulting in significant financial losses. Your CIO is strongly agreeing to move the application to AWS. While working on achieving buy-in from the other company executives, he asks you to develop a disaster recovery plan to help improve Business continuity in the short term. He specifies a target Recovery Time Objective (RTO) of 4 hours and a Recovery Point Objective (RPO) of 1 hour or less. He also asks you to implement the solution within 2 weeks. Your database is 200GB in size and you have a 20Mbps Internet connection. How would you do this while minimizing costs?</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="True">Create an EBS backed private AMI which includes a fresh install or your application. Setup a script in your data center to backup the local database every 1 hour and to encrypt and copy the resulting file to an S3 bucket using multi-part upload.</choice>
      <choice correct="False">Install your application on a compute-optimized EC2 instance capable of supporting the application’s average load synchronously replicate transactions from your on-premises database to a database instance in AWS across a secure Direct Connect connection.</choice>
      <choice correct="False">Deploy your application on EC2 instances within an Auto Scaling group across multiple availability zones asynchronously replicate transactions from your on-premises database to a database instance in AWS across a secure VPN connection.</choice>
      <choice correct="False">Create an EBS backed private AMI that includes a fresh install of your application. Develop a Cloud Formation template which includes your Mil and the required EC2. Auto-Scaling and ELB resources to support</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>An ERP application is deployed across multiple AZs in a single region. In the event of failure, the Recovery Time Objective (RTO) must be less than 3 hours, and the Recovery Point Objective (RPO) must be 15 minutes the customer realizes that data corruption occurred roughly 1.5 hours ago. What DR strategy could be used to achieve this RTO and RPO in the event of this kind of failure?</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="False">Take hourly DB backups to S3, with transaction logs stored in S3 every 5 minutes.</choice>
      <choice correct="False">Use synchronous database master-slave replication between two availability zones.</choice>
      <choice correct="True">Take hourly DB backups to EC2 Instance store volumes with transaction logs stored In S3 every 5 minutes.</choice>
      <choice correct="False">Take 15 minute DB backups stored In Glacier with transaction logs stored in S3 every 5 minutes.</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>Your company hosts a social media site supporting users in multiple countries. You have been asked to provide a highly available design tor the application that leverages multiple regions tor the most recently accessed content and latency sensitive portions of the wet) site The most latency sensitive component of the application involves reading user preferences to support web site personalization and ad selection. In addition to running your application in multiple regions, which option will support this application’s requirements?</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="True">Serve user content from S3. CloudFront and use Route53 latency-based routing between ELBs in each region Retrieve user preferences from a local DynamoDB table in each region and leverage SQS to capture changes to user preferences with SOS workers for propagating updates to each table.</choice>
      <choice correct="False">Use the S3 Copy API to copy recently accessed content to multiple regions and serve user content from S3. CloudFront with dynamic content and an ELB in each region Retrieve user preferences from an ElasticCache cluster in each region and leverage SNS notifications to propagate user preference changes to a worker node in each region.</choice>
      <choice correct="False">Use the S3 Copy API to copy recently accessed content to multiple regions and serve user content from S3 CloudFront and Route53 latency-based routing Between ELBs In each region Retrieve user preferences from a DynamoDB table and leverage SQS to capture changes to user preferences with SOS workers for propagating DynamoDB updates.</choice>
      <choice correct="False">Serve user content from S3. CloudFront with dynamic content, and an ELB in each region Retrieve user preferences from an ElastiCache cluster in each region and leverage Simple Workflow (SWF) to manage the propagation of user preferences from a centralized OB to each ElastiCache cluster.</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p></p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="False">up a message queue between EC2 instances which are used as batch processors Cloud Watch monitors thenumber of Job requests (queued messages) and an Auto Scaling group adds or deletes batch serversautomatically based on parameters set in Cloud Watch alarms. You can use this architecture to implementwhich of the following features in a cost effective and efficient manner?</choice>
      <choice correct="False">Reduce the overall lime for executing jobs through parallel processing by allowing a busy EC2 instance that receives a message to pass it to the next instance in a daisy-chain setup.</choice>
      <choice correct="True">Implement fault tolerance against EC2 instance failure since messages would remain in SQS and worn can continue with recovery of EC2 instances implement fault tolerance against SQS failure by backing up messages to S3.</choice>
      <choice correct="False">Implement message passing between EC2 instances within a batch by exchanging messages through SOS.</choice>
      <choice correct="False">Coordinate number of EC2 instances with number of job requests automatically thus Improving cost effectiveness.</choice>
      <choice correct="False">Handle high priority jobs before lower priority jobs by assigning a priority metadata field to SQS messages.</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>You have deployed a web application targeting a global audience across multiple AWS Regions under the domain name.example.com. You decide to use Route53 Latency-Based Routing to serve web requests to users from the region closest to the user. To provide business continuity in the event of server downtime you configure weighted record sets associated with two web servers in separate Availability Zones per region. Dunning a DR test you notice that when you disable all web servers in one of the regions Route53 does not automatically direct all users to the other region. What could be happening? (Choose 2 answers)</p>
  <choiceresponse>
    <checkboxgroup>
      <choice correct="False">Latency resource record sets cannot be used in combination with weighted resource record sets.</choice>
      <choice correct="True">You did not setup an http health check tor one or more of the weighted resource record sets associated with me disabled web servers.</choice>
      <choice correct="False">The value of the weight associated with the latency alias resource record set in the region with the disabled servers is higher than the weight for the other region.</choice>
      <choice correct="True">One of the two working web servers in the other region did not pass its HTTP health check.</choice>
      <choice correct="False">You did not set “Evaluate Target Health” to “Yes” on the latency alias resource record set associated with example com in the region where you disabled the servers.</choice>
    </checkboxgroup>
  </choiceresponse>
</problem>
<problem>
  <p>Your startup wants to implement an order fulfillment process for selling a personalized gadget that needs an average of 3-4 days to produce with some orders taking up to 6 months you expect 10 orders per day on your first day. 1000 orders per day after 6 months and 10,000 orders after 12 months. Orders coming in are checked for consistency men dispatched to your manufacturing plant for production quality control packaging shipment and payment processing If the product does not meet the quality standards at any stage of the process employees may force the process to repeat a step Customers are notified via email about order status and any critical issues with their orders such as payment failure. Your case architecture includes AWS Elastic Beanstalk for your website with an RDS MySQL instance for customer data and orders. How can you implement the order fulfillment process while making sure that the emails are delivered reliably?</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="False">Add a business process management application to your Elastic Beanstalk app servers and re-use the ROS database for tracking order status use one of the Elastic Beanstalk instances to send emails to customers.</choice>
      <choice correct="False">Use SWF with an Auto Scaling group of activity workers and a decider instance in another Auto Scaling group with min/max=1 Use the decider instance to send emails to customers.</choice>
      <choice correct="True">Use SWF with an Auto Scaling group of activity workers and a decider instance in another Auto Scaling group with min/max=1 use SES to send emails to customers.</choice>
      <choice correct="False">Use an SQS queue to manage all process tasks Use an Auto Scaling group of EC2 Instances that poll the tasks and execute them. Use SES to send emails to customers.</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>The Trusted Advisor service provides insight regarding which four categories of an AWS account?</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="False">Security, fault tolerance, high availability, and connectivity</choice>
      <choice correct="False">Security, access control, high availability, and performance</choice>
      <choice correct="True">Performance, cost optimization, security, and fault tolerance</choice>
      <choice correct="False">Performance, cost optimization, access control, and connectivity</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>Your system recently experienced down time during the troubleshooting process. You found that a new administrator mistakenly terminated several production EC2 instances. Which of the following strategies will help prevent a similar situation in the future? The administrator still must be able to: – launch, start stop, and terminate development resources. – launch and start production instances.</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="False">Create an IAM user, which is not allowed to terminate instances by leveraging production EC2 termination protection.</choice>
      <choice correct="False">Leverage resource based tagging along with an IAM user, which can prevent specific users from terminating production EC2 resources.</choice>
      <choice correct="False">Leverage EC2 termination protection and multi-factor authentication, which together require users to authenticate before terminating EC2 instances</choice>
      <choice correct="True">Create an IAM user and apply an IAM role which prevents users from terminating production EC2 instances.</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>A customer has established an AWS Direct Connect connection to AWS. The link is up and routes are being advertised from the customer’s end, however the customer is unable to connect from EC2 instances inside its VPC to servers residing in its datacenter. Which of the following options provide a viable solution to remedy this situation? (Choose 2 answers)</p>
  <choiceresponse>
    <checkboxgroup>
      <choice correct="True">Add a route to the route table with an iPsec VPN connection as the target.</choice>
      <choice correct="False">Enable route propagation to the virtual pinnate gateway (VGW).</choice>
      <choice correct="True">Enable route propagation to the customer gateway (CGW).</choice>
      <choice correct="False">Modify the route table of all Instances using the ‘route’ command.</choice>
      <choice correct="False">Modify the Instances VPC subnet route table by adding a route back to the customer’s on-premises environment.</choice>
    </checkboxgroup>
  </choiceresponse>
</problem>
<problem>
  <p>A company is preparing to give AWS Management Console access to developers Company policy mandates identity federation and role-based access control. Roles are currently assigned using groups in the corporate Active Directory. What combination of the following will give developers access to the AWS console? (Select 2) Choose 2 answers</p>
  <choiceresponse>
    <checkboxgroup>
      <choice correct="True">AWS Directory Service AD Connector</choice>
      <choice correct="False">AWS Directory Service Simple AD</choice>
      <choice correct="True">AWS Identity and Access Management groups</choice>
      <choice correct="False">AWS identity and Access Management roles</choice>
      <choice correct="False">AWS identity and Access Management users</choice>
    </checkboxgroup>
  </choiceresponse>
</problem>
<problem>
  <p>A company has configured and peered two VPCs: VPC-1 and VPC-2. VPC-1 contains only private subnets, and VPC-2 contains only public subnets. The company uses a single AWS Direct Connect connection and private virtual interface to connect their on-premises network with VPC-1. Which two methods increases the fault tolerance of the connection to VPC-1? Choose 2 answers</p>
  <choiceresponse>
    <checkboxgroup>
      <choice correct="False">Establish a hardware VPN over the internet between VPC-2 ana the on-premises network.</choice>
      <choice correct="True">Establish a hardware VPN over the internet between VPC-1 and the on-premises network.</choice>
      <choice correct="True">Establish a new AWS Direct Connect connection and private virtual interface in the same region as VPC-2.</choice>
      <choice correct="False">Establish a new AWS Direct Connect connection and private virtual interface in a different AWS region than VPC-1.</choice>
      <choice correct="False">Establish a new AWS Direct Connect connection and private virtual interface in the same AWS region as VPC-1</choice>
    </checkboxgroup>
  </choiceresponse>
</problem>
