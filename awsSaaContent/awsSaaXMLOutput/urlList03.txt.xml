<problem>
  <p>Your company has an on-premises multi-tier PHP web application, which recently experienced downtime due to a large burst In web traffic due to a company announcement Over the coming days, you are expecting similar announcements to drive similar unpredictable bursts, and are looking to find ways to quickly improve your infrastructures ability to handle unexpected increases in traffic. The application currently consists of 2 tiers A web tier which consists of a load balancer and several Linux Apache web servers as well as a database tier which hosts a Linux server hosting a MySQL database. Which scenario below will provide full site functionality, while helping to improve the ability of your application in the short timeframe required?</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="False">Offload traffic from on-premises environment Setup a CloudFront distribution and configure CloudFront to cache objects from a custom origin Choose to customize your object cache behavior, and select a TTL that objects should exist in cache.</choice>
      <choice correct="False">Migrate to AWS Use VM import ‘Export to quickly convert an on-premises web server to an AMI create an Auto Scaling group, which uses the imported AMI to scale the web tier based on incoming traffic Create an RDS read replica and setup replication between the RDS instance and on-premises MySQL server to migrate the database.</choice>
      <choice correct="True">Failover environment: Create an S3 bucket and configure it tor website hosting Migrate your DNS to Route53 using zone (lie import and leverage Route53 DNS failover to failover to the S3 hosted website.</choice>
      <choice correct="False">Hybrid environment Create an AMI which can be used of launch web serfers in EC2 Create an Auto Scaling group which uses the * AMI to scale the web tier based on incoming traffic Leverage Elastic Load Balancing to balance traffic between on-premises web servers and those hosted in AWS.</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>Your company produces customer commissioned one-of-a-kind skiing helmets combining nigh fashion with custom technical enhancements Customers can show oft their Individuality on the ski slopes and have access to head-up-displays. GPS rear-view cams and any other technical innovation they wish to embed in the helmet. The current manufacturing process is data rich and complex including assessments to ensure that the custom electronics and materials used to assemble the helmets are to the highest standards Assessments are a mixture of human and automated assessments you need to add a new set of assessment to model the failure modes of the custom electronics using GPUs with CUD</p>
  <choiceresponse>
    <checkboxgroup>
      <choice correct="True">across a cluster of servers with low latency networking. What architecture would allow you to automate the existing process using a hybrid approach and ensure that the architecture can support the evolution of processes over time?  Use AWS Data Pipeline to manage movement of data &amp; meta-data and assessments Use an auto-scaling group of G2 instances in a placement group.</choice>
      <choice correct="True">across a cluster of servers with low latency networking. What architecture would allow you to automate the existing process using a hybrid approach and ensure that the architecture can support the evolution of processes over time?  Use AWS Data Pipeline to manage movement of data &amp; meta-data and assessments Use an auto-scaling group of G2 instances in a placement group.</choice>
      <choice correct="False">Use Amazon Simple Workflow (SWF) 10 manages assessments, movement of data &amp; meta-data Use an autoscaling group of G2 instances in a placement group.</choice>
      <choice correct="False">Use Amazon Simple Workflow (SWF) lo manages assessments movement of data &amp; meta-data Use an autoscaling group of C3 instances with SR-IOV (Single Root I/O Virtualization).</choice>
      <choice correct="False">Use AWS data Pipeline to manage movement of data &amp; meta-data and assessments use auto-scaling group of C3 with SR-IOV (Single Root I/O virtualization).</choice>
    </checkboxgroup>
  </choiceresponse>
</problem>
<problem>
  <p>You are designing a multi-platform web application for AWS The application will run on EC2 instances and will be accessed from PCs. tablets and smart phones Supported accessing platforms are Windows. MACOS. IOS and Android Separate sticky session and SSL certificate setups are required for different platform types which of the following describes the most cost effective and performance efficient architecture setup?</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="False">Setup a hybrid architecture to handle session state and SSL certificates on-prem and separate EC2 Instance groups running web applications for different platform types running in a VPC.</choice>
      <choice correct="False">Set up one ELB for all platforms to distribute load among multiple instance under it Each EC2 instance implements ail functionality for a particular platform.</choice>
      <choice correct="False">Set up two ELBs The first ELB handles SSL certificates for all platforms and the second ELB handles session stickiness for all platforms for each ELB run separate EC2 instance groups to handle the web application for each platform.</choice>
      <choice correct="True">Assign multiple ELBS to an EC2 instance or group of EC2 instances running the common components of the web application, one ELB for each platform type Session stickiness and SSL termination are done at the ELBs.</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>A corporate web application is deployed within an Amazon Virtual Private Cloud (VPC) and is connected to the corporate data center via an iPsec VPN. The application must authenticate against the on-premises LDAP server. After authentication, each logged-in user can only access an Amazon Simple Storage Space (S3) keyspace specific to that user. Which two approaches can satisfy these objectives? (Choose 2 answers)</p>
  <choiceresponse>
    <checkboxgroup>
      <choice correct="True">Develop an identity broker that authenticates against IAM security Token service to assume a IAM role in order to get temporary AWS security credentials The application calls the identity broker to get AWS temporary security credentials with access to the appropriate S3 bucket.</choice>
      <choice correct="False">The application authenticates against LOAP and retrieves the name of an IAM role associated with the user. The application then cails the IAM Security Token Service to assume that IAM role The application can use the temporary credentials to access the appropriate S3 bucket.</choice>
      <choice correct="False">Develop an identity broker that authenticates against LDAP and then calls IAM Security Token Service to get IAM federated user credentials The application calls the identity broker to get IAM federated user credentials with access to the appropriate S3 bucket.</choice>
      <choice correct="False">The application authenticates against LDAP the application then calls the AWS identity and Access Management (IAM) Security service to log in to IAM using the LDAP credentials the application can use the IAM temporary credentials to access the appropriate S3 bucket.</choice>
      <choice correct="True">The application authenticates against IAM Security Token Service using the LDAP credentials the application uses those temporary AWS security credentials to access the appropriate S3 bucket.</choice>
    </checkboxgroup>
  </choiceresponse>
</problem>
<problem>
  <p>Your website is serving on-demand training videos to your workforce. Videos are uploaded monthly in high resolution MP4 format. Your workforce is distributed globally often on the move and using company-provided tablets that require the HTTP Live Streaming (HLS) protocol to watch a video. Your company has no video transcoding expertise and it required you may need to pay for a consultant. How do you implement the most cost-efficient architecture without compromising high availability and quality of video delivery’?</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="False">Elastic Transcoder to transcode original high-resolution MP4 videos to HLS S3 to host videos with Utecycle Management to archive original flies to Glacier after a few days CloudFront to serve HLS transcoded videos from S3</choice>
      <choice correct="False">A video transcoding pipeline running on EC2 using SQS to distribute tasks and Auto Scaling to adjust the number or nodes depending on the length of the queue S3 to host videos with Lifecycle Management to archive all files to Glacier after a few days CloudFront to serve HLS transcoding videos from Glacier</choice>
      <choice correct="False">Elastic Transcoder to transcode original nigh-resolution MP4 videos to HLS EBS volumes to host videos and EBS snapshots to incrementally backup original rues after a fe days.CioudFront to serve HLS transcoded videos from EC2.</choice>
      <choice correct="True">A video transcoding pipeline running on EC2 using SOS to distribute tasks and Auto Scaling to adjust the number of nodes depending on the length of the queue E8S volumes to host videos and EBS snapshots to incrementally backup original files after a few days CloudFront to serve HLS transcoded videos from EC2</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>You’ve been hired to enhance the overall security posture for a very large e-commerce site They have a well architected multi-tier application running in a VPC that uses ELBs in front of both the web and the app tier with static assets served directly from S3 They are using a combination of RDS and DynamoOB for their dynamic data and then archiving nightly into S3 for further processing with EMR They are concerned because they found questionable log entries and suspect someone is attempting to gain unauthorized access. Which approach provides a cost effective scalable mitigation to this kind of attack?</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="False">Recommend mat they lease space at a DirectConnect partner location and establish a 1G DirectConnect connection to tneirvPC they would then establish Internet connectivity into their space, filter the traffic in hardware Web Application Firewall (WAF). And then pass the traffic through the DirectConnect connection into their application running in their VPC.</choice>
      <choice correct="False">Add previously identified hostile source IPs as an explicit INBOUND DENY NACL to the web tier subnet.</choice>
      <choice correct="True">Add a WAF tier by creating a new ELB and an AutoScalmg group of EC2 Instances running a host-based WAF They would redirect Route 53 to resolve to the new WAF tier ELB The WAF tier would thier pass the traffic to the current web tier The web tier Security Groups would be updated to only allow traffic from the WAF tier Security Group</choice>
      <choice correct="False">Remove all but TLS 1 2 from the web tier ELB and enable Advanced Protocol Filtering This will enable the ELB itself to perform WAF functionality.</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>Your company previously configured a heavily used, dynamically routed VPN connection between your onpremises data center and AWS. You recently provisioned a DirectConnect connection and would like to start using the new connection. After configuring DirectConnect settings in the AWS Console, which of the following options win provide the most seamless transition for your users?</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="False">Delete your existing VPN connection to avoid routing loops configure your DirectConnect router with the appropriate settings and verity network traffic is leveraging DirectConnect.</choice>
      <choice correct="False">Configure your DireclConnect router with a higher 8GP priority man your VPN router, verify network traffic is leveraging Directconnect and then delete your existing VPN connection.</choice>
      <choice correct="False">Update your VPC route tables to point to the DirectConnect connection configure your DirectConnect router with the appropriate settings verify network traffic is leveraging DirectConnect and then delete the VPN connection.</choice>
      <choice correct="True">Configure your DireclConnect router, update your VPC route tables to point to the DirectConnect connection, configure your VPN connection with a higher BGP pointy. And verify network traffic is leveraging the DirectConnect connection.</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>You are designing the network infrastructure for an application server in Amazon VPC Users will access all the application instances from the Internet as well as from an on-premises network The on-premises network is connected to your VPC over an AWS Direct Connect link. How would you design routing to meet the above requirements?</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="True">Configure a single routing Table with a default route via the Internet gateway Propagate a default route via BGP on the AWS Direct Connect customer router Associate the routing table with all VPC subnets.</choice>
      <choice correct="False">Configure a single routing table with a default route via the internet gateway Propagate specific routes for the on-premises networks via BGP on the AWS Direct Connect customer router Associate the routing table with all VPC subnets.</choice>
      <choice correct="False">Configure a single routing table with two default routes: one to the internet via an Internet gateway the other to the on-premises network via the VPN gateway use this routing table across all subnets in your VPC.</choice>
      <choice correct="False">Configure two routing tables one that has a default route via the Internet gateway and another that has a default route via the VPN gateway Associate both routing tables with each VPC subnet.</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>You are implementing AWS Direct Connect. You intend to use AWS public service end points such as Amazon S3, across the AWS Direct Connect link. You want other Internet traffic to use your existing link to an Internet Service Provider. What is the correct way to configure AWS Direct connect for access to services such as Amazon S3?</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="False">Configure a public Interface on your AWS Direct Connect link Configure a static route via your AWS Direct Connect link that points to Amazon S3 Advertise a default route to AWS using BGP.</choice>
      <choice correct="False">Create a private interface on your AWS Direct Connect link. Configure a static route via your AWS Direct connect link that points to Amazon S3 Configure specific routes to your network in your VPC.</choice>
      <choice correct="True">Create a public interface on your AWS Direct Connect link Redistribute BGP routes into your existing routing infrastructure advertise specific routes for your network to AWS.</choice>
      <choice correct="False">Create a private interface on your AWS Direct connect link. Redistribute BGP routes into your existing routing infrastructure and advertise a default route to AWS.</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>A web company is looking to implement an external payment service into their highly available application deployed in a VPC Their application EC2 instances are behind a public lacing ELB Auto scaling is used to add additional instances as traffic increases under normal load the application runs 2 instances in the Auto Scaling group but at peak it can scale 3x in size. The application instances need to communicate with the payment service over the Internet which requires whitelisting of all public IP addresses used to communicate with it. A maximum of 4 whitelisting IP addresses are allowed at a time and can be added through an API. How should they architect their solution?</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="False">Route payment requests through two NAT instances setup for High Availability and whitelist the Elastic IP addresses attached to the MAT instances.</choice>
      <choice correct="True">Whitelist the VPC Internet Gateway Public IP and route payment requests through the Internet Gateway.</choice>
      <choice correct="False">Whitelist the ELB IP addresses and route payment requests from the Application servers through the ELB.</choice>
      <choice correct="False">Automatically assign public IP addresses to the application instances in the Auto Scaling group and run a script on boot that adds each instances public IP address to the payment validation whitelist API.</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>You’ve been brought in as solutions architect to assist an enterprise customer with their migration of an ecommerce platform to Amazon Virtual Private Cloud (VPC) The previous architect has already deployed a 3- tier VPC. The configuration is as follows: VPC vpc-2f8t&gt;C447</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="False">NACL acl-2080c448Subnets and Route Tables:Web server’s subnet-258Dc44dApplication server’s suDnet-248bc44cDatabase server’s subnet-9189c6f9Route Tables:rrb-218DC449rtb-238bc44bAssociations:subnet-258bc44d: rtb-2i8bc449Subnet-248DC44C rtb-238tX44bsubnet-9189c6f9 rtb-238Dc 44bYou are now ready to begin deploying EC2 instances into the VPC Web servers must have direct access to theinternet Application and database servers cannot have direct access to the internet.Which configuration below will allow you the ability to remotely administer your application and databaseservers, as well as allow these servers to retrieve updates from the Internet?</choice>
      <choice correct="True">Create a bastion and NAT Instance in subnet-248bc44c and add a route from rtb-238bc44b to subnet- 258bc44d.</choice>
      <choice correct="False">Add a route from rtD-238bc44D to igw-2d8bc445 and add a bastion and NAT instance within suonet- 248bc44c.</choice>
      <choice correct="False">Create a bastion and MAT Instance In subnet-258bc44d. Add a route from rtb-238bc44b to igw-2d8bc445. And a new NACL that allows access between subnet-258bc44d and subnet-248bc44c.</choice>
      <choice correct="False">Create a bastion and mat instance in suDnet-258Dc44d and add a route from rtD-238Dc44D to the mat instance.</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>You are tasked with moving a legacy application from a virtual machine running Inside your datacenter to an Amazon VPC Unfortunately this app requires access to a number of on-premises services and no one who configured the app still works for your company. Even worse there’s no documentation for it. What will allow the application running inside the VPC to reach back and access its internal dependencies without being reconfigured? (Choose 3 answers)</p>
  <choiceresponse>
    <checkboxgroup>
      <choice correct="True">An AWS Direct Connect link between the VPC and the network housing the internal services.</choice>
      <choice correct="False">An Internet Gateway to allow a VPN connection.</choice>
      <choice correct="True">An Elastic IP address on the VPC instance</choice>
      <choice correct="False">An IP address space that does not conflict with the one on-premises</choice>
      <choice correct="False">Entries in Amazon Route 53 that allow the Instance to resolve its dependencies’ IP addresses</choice>
      <choice correct="True">A VM Import of the current virtual machine</choice>
    </checkboxgroup>
  </choiceresponse>
</problem>
<problem>
  <p>You are designing Internet connectivity for your VPC. The Web servers must be available on the Internet. The application must have a highly available architecture. Which alternatives should you consider? (Choose 2 answers)</p>
  <choiceresponse>
    <checkboxgroup>
      <choice correct="False">Configure a NAT instance in your VPC Create a default route via the NAT instance and associate it with all subnets Configure a DNS A record that points to the NAT instance public IP address.</choice>
      <choice correct="True">Configure a CloudFront distribution and configure the origin to point to the private IP addresses of your Web servers Configure a Route53 CNAME record to your CloudFront distribution.</choice>
      <choice correct="True">Place all your web servers behind EL8 Configure a Route53 CNMIE to point to the ELB DNS name.</choice>
      <choice correct="False">Assign BPs to all web servers. Configure a Route53 record set with all EIPs. With health checks and DNS failover.</choice>
      <choice correct="False">Configure ELB with an EIP Place all your Web servers behind ELB Configure a Route53 A record that points to the EIP.</choice>
    </checkboxgroup>
  </choiceresponse>
</problem>
<problem>
  <p>You’re running an application on-premises due to its dependency on non-x86 hardware and want to use AWS for data backup. Your backup application is only able to write to POSIX-compatible block-based storage. You have 140TB of data and would like to mount it as a single folder on your file server Users must be able to access portions of this data while the backups are taking place. What backup solution would be most appropriate for this use case?</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="False">Use Storage Gateway and configure it to use Gateway Cached volumes.</choice>
      <choice correct="False">Configure your backup software to use S3 as the target for your data backups.</choice>
      <choice correct="True">Configure your backup software to use Glacier as the target for your data backups.</choice>
      <choice correct="False">Use Storage Gateway and configure it to use Gateway Stored volumes.</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>You have deployed a three-tier web application in a VPC with a CIOR block of 10 0 0 0/28 You initially deploy two web servers, two application servers, two database servers and one NAT instance tor a total of seven EC2 instances The web. Application and database servers are deployed across two availability zones (AZs). You also deploy an ELB in front of the two web servers, and use Route53 for DNS Web (raffle gradually increases in the first few days following the deployment, so you attempt to double the number of instances in each tier of the application to handle the new load unfortunately some of these new instances fail to launch. Which of the following could De the root caused? (Choose 2 answers)</p>
  <choiceresponse>
    <checkboxgroup>
      <choice correct="False">The Internet Gateway (IGW) of your VPC has scaled-up adding more instances to handle the traffic spike, reducing the number of available private IP addresses for new instance launches.</choice>
      <choice correct="False">AWS reserves one IP address In each subnet’s CIDR block for Route53 so you do not have enough addresses left to launch all of the new EC2 instances.</choice>
      <choice correct="True">AWS reserves the first and the last private IP address in each subnet’s CIDR block so you do not have enough addresses left to launch all of the new EC2 instances.</choice>
      <choice correct="True">The ELB has scaled-up. Adding more instances to handle the traffic reducing the number of available private IP addresses for new instance launches.</choice>
      <choice correct="False">AWS reserves the first tour and the last IP address in each subnet’s CIDR block so you do not have enough addresses left to launch all of the new EC2 instances.</choice>
    </checkboxgroup>
  </choiceresponse>
</problem>
<problem>
  <p>You are the new IT architect in a company that operates a mobile sleep tracking application When activated at night, the mobile app is sending collected data points of 1 kilobyte every 5 minutes to your backend The backend takes care of authenticating the user and writing the data points into an Amazon DynamoDB table. Every morning, you scan the table to extract and aggregate last night’s data on a per user basis, and store the results in Amazon S3. Users are notified via Amazon SMS mobile push notifications that new data is available, which is parsed and visualized by (he mobile app Currently you have around 100k users who are mostly based out of North America. You have been tasked to optimize the architecture of the backend system to lower cost what would you recommend? (Choose 2 answers)</p>
  <choiceresponse>
    <checkboxgroup>
      <choice correct="False">Create a new Amazon DynamoDB (able each day and drop the one for the previous day after its data is on Amazon S3.</choice>
      <choice correct="True">Have the mobile app access Amazon DynamoDB directly instead of JSON files stored on Amazon S3.</choice>
      <choice correct="False">Introduce an Amazon SQS queue to buffer writes to the Amazon DynamoDB table and reduce provisioned write throughput.</choice>
      <choice correct="True">Introduce Amazon Elasticache lo cache reads from the Amazon DynamoDB table and reduce provisioned read throughput.</choice>
      <choice correct="False">Write data directly into an Amazon Redshift cluster replacing both Amazon DynamoDB and Amazon S3.</choice>
    </checkboxgroup>
  </choiceresponse>
</problem>
<problem>
  <p>You are designing a social media site and are considering how to mitigate distributed denial-of-service (DDoS) attacks. Which of the below are viable mitigation techniques? (Choose 3 answers)</p>
  <choiceresponse>
    <checkboxgroup>
      <choice correct="False">Add multiple elastic network interfaces (ENIs) to each EC2 instance to increase the network bandwidth.</choice>
      <choice correct="True">Use dedicated instances to ensure that each instance has the maximum performance possible.</choice>
      <choice correct="False">Use an Amazon CloudFront distribution for both static and dynamic content.</choice>
      <choice correct="True">Use an Elastic Load Balancer with auto scaling groups at the web. App and Amazon Relational Database Service (RDS) tiers</choice>
      <choice correct="False">Add alert Amazon CloudWatch to look for high Network in and CPU utilization.</choice>
      <choice correct="True">Create processes and capabilities to quickly add and remove rules to the instance OS firewall.</choice>
    </checkboxgroup>
  </choiceresponse>
</problem>
<problem>
  <p>You are migrating a legacy client-server application to AWS The application responds to a specific DNS domain (e g www example com) and has a 2-tier architecture, with multiple application servers and a database server Remote clients use TCP to connect to the application servers. The application servers need to know the IP address of the clients in order to function properly and are currently taking that information from the TCP socket A Multi-AZ RDS MySQL instance will be used for the database. During the migration you can change the application code but you have to file a change request. How would you implement the architecture on AWS In order to maximize scalability and high ability?</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="False">File a change request to implement Proxy Protocol support In the application Use an EL8 with a TCP Listener and Proxy Protocol enabled to distribute load on two application servers in different AZs.</choice>
      <choice correct="False">File a change request to Implement Cross-Zone support in the application Use an EL8 with a TCP Listener and Cross-Zone Load Balancing enabled, two application servers in different AZs.</choice>
      <choice correct="False">File a change request to implement Latency Based Routing support in the application Use Route 53 with Latency Based Routing enabled to distribute load on two application servers in different AZs.</choice>
      <choice correct="True">File a change request to implement Alias Resource support in the application Use Route 53 Alias Resource Record to distribute load on two application servers in different AZs.</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>Your fortune 500 company has under taken a TCO analysis evaluating the use of Amazon S3 versus acquiring more hardware The outcome was that ail employees would be granted access to use Amazon S3 for storage of their personal documents. Which of the following will you need to consider so you can set up a solution that incorporates single sign-on from your corporate AD or LDAP directory and restricts access for each user to a designated user folder in a bucket? (Choose 3 Answers)</p>
  <choiceresponse>
    <checkboxgroup>
      <choice correct="True">Setting up a federation proxy or identity provider</choice>
      <choice correct="True">Using AWS Security Token Service to generate temporary tokens</choice>
      <choice correct="True">Tagging each folder in the bucket</choice>
      <choice correct="False">Configuring IAM role</choice>
      <choice correct="False">Setting up a matching IAM user for every user in your corporate directory that needs access to a folder in the bucket</choice>
    </checkboxgroup>
  </choiceresponse>
</problem>
<problem>
  <p>Your department creates regular analytics reports from your company’s log files All log data is collected in Amazon S3 and processed by daily Amazon Elastic MapReduce (EMR) jobs that generate daily PDF reports and aggregated tables in CSV format for an Amazon Redshift data warehouse. Your CFO requests that you optimize the cost structure for this system. Which of the following alternatives will lower costs without compromising average performance of the system or data integrity for the raw data?</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="False">Use reduced redundancy storage (RRS) for PDF and csv data in Amazon S3. Add Spot instances to Amazon EMR jobs Use Reserved Instances for Amazon Redshift.</choice>
      <choice correct="True">Use reduced redundancy storage (RRS) for all data in S3. Use a combination of Spot instances and Reserved Instances for Amazon EMR jobs use Reserved instances for Amazon Redshift.</choice>
      <choice correct="False">Use reduced redundancy storage (RRS) for all data in Amazon S3 Add Spot Instances to Amazon EMR jobs Use Reserved Instances for Amazon Redshitf.</choice>
      <choice correct="False">Use reduced redundancy storage (RRS) for PDF and csv data in S3 Add Spot Instances to EMR jobs Use Spot Instances for Amazon Redshift.</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>You have an application running on an EC2 Instance which will allow users to download flies from a private S3 bucket using a pre-assigned URL. Before generating the URL the application should verify the existence of the file in S3. How should the application use AWS credentials to access the S3 bucket securely?</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="False">Use the AWS account access Keys the application retrieves the credentials from the source code of the application.</choice>
      <choice correct="True">Create a IAM user for the application with permissions that allow list access to the S3 bucket launch the instance as the IAM user and retrieve the IAM user’s credentials from the EC2 instance user data.</choice>
      <choice correct="False">Create an IAM role for EC2 that allows list access to objects in the S3 bucket. Launch the instance with the role, and retrieve the role’s credentials from the EC2 Instance metadata</choice>
      <choice correct="False">Create an IAM user for the application with permissions that allow list access to the S3 bucket. The application retrieves the IAM user credentials from a temporary directory with permissions that allow read access only to the application user.</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>You have a periodic Image analysis application that gets some files In Input analyzes them and tor each file writes some data in output to a ten file the number of files in input per day is high and concentrated in a few hours of the day. Currently you have a server on EC2 with a large EBS volume that hosts the input data and the results it takes almost 20 hours per day to complete the process What services could be used to reduce the elaboration time and improve the availability of the solution?</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="False">S3 to store I/O files. SQS to distribute elaboration commands to a group of hosts working in parallel. Auto scaling to dynamically size the group of hosts depending on the length of the SQS queue</choice>
      <choice correct="False">EBS with Provisioned IOPS (PIOPS) to store I/O files. SNS to distribute elaboration commands to a group of hosts working in parallel Auto Scaling to dynamically size the group of hosts depending on the number of SNS notifications</choice>
      <choice correct="True">S3 to store I/O files, SNS to distribute evaporation commands to a group of hosts working in parallel. Auto scaling to dynamically size the group of hosts depending on the number of SNS notifications</choice>
      <choice correct="False">EBS with Provisioned IOPS (PIOPS) to store I/O files SOS to distribute elaboration commands to a group of hosts working in parallel Auto Scaling to dynamically size the group ot hosts depending on the length of the SQS queue.</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>Your company is getting ready to do a major public announcement of a social media site on AWS. The website is running on EC2 instances deployed across multiple Availability Zones with a Multi-AZ RDS MySQL Extra Large DB Instance. The site performs a high number of small reads and writes per second and relies on an eventual consistency model. After comprehensive tests you discover that there is read contention on RDS MySQL. Which are the best approaches to meet these requirements? (Choose 2 answers)</p>
  <choiceresponse>
    <checkboxgroup>
      <choice correct="True">Deploy ElasticCache in-memory cache running in each availability zone</choice>
      <choice correct="False">Implement sharding to distribute load to multiple RDS MySQL instances</choice>
      <choice correct="True">Increase the RDS MySQL Instance size and Implement provisioned IOPS</choice>
      <choice correct="False">Add an RDS MySQL read replica in each availability zone</choice>
    </checkboxgroup>
  </choiceresponse>
</problem>
<problem>
  <p>Your company policies require encryption of sensitive data at rest. You are considering the possible options for protecting data while storing it at rest on an EBS data volume, attached to an EC2 instance. Which of these options would allow you to encrypt your data at rest? (Choose 3 answers)</p>
  <choiceresponse>
    <checkboxgroup>
      <choice correct="False">Implement third party volume encryption tools</choice>
      <choice correct="False">Do nothing as EBS volumes are encrypted by default</choice>
      <choice correct="True">Encrypt data inside your applications before storing it on EBS</choice>
      <choice correct="True">Encrypt data using native data encryption drivers at the file system level</choice>
      <choice correct="True">Implement SSL/TLS for all services running on the server</choice>
    </checkboxgroup>
  </choiceresponse>
</problem>
<problem>
  <p>A company is running a batch analysis every hour on their main transactional DB. running on an RDS MySQL instance to populate their central Data Warehouse running on Redshift During the execution of the batch their transactional applications are very slow When the batch completes they need to update the top management dashboard with the new data The dashboard is produced by another system running on-premises that is currently started when a manually-sent email notifies that an update is required The on-premises system cannot be modified because is managed by another team. How would you optimize this scenario to solve performance issues and automate the process as much as possible?</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="False">Replace RDS with Redshift for the batch analysis and SNS to notify the on-premises system to update the dashboard</choice>
      <choice correct="False">Replace ROS with Redsnift for the oaten analysis and SQS to send a message to the on-premises system to update the dashboard</choice>
      <choice correct="False">Create an RDS Read Replica for the batch analysis and SNS to notify me on-premises system to update the dashboard</choice>
      <choice correct="True">Create an RDS Read Replica for the batch analysis and SQS to send a message to the on-premises system to update the dashboard.</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>You require the ability to analyze a customer’s clickstream data on a website so they can do behavioral analysis. Your customer needs to know what sequence of pages and ads their customer clicked on. This data will be used in real time to modify the page layouts as customers click through the site to increase stickiness and advertising click-through. Which option meets the requirements for captioning and analyzing this data?</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="False">Log clicks in weblogs by URL store to Amazon S3, and then analyze with Elastic MapReduce</choice>
      <choice correct="True">Push web clicks by session to Amazon Kinesis and analyze behavior using Kinesis workers</choice>
      <choice correct="False">Write click events directly to Amazon Redshift and then analyze with SQL</choice>
      <choice correct="False">Publish web clicks by session to an Amazon SQS queue men periodically drain these events to Amazon RDS and analyze with sol</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>A newspaper organization has a on-premises application which allows the public to search its back catalogue and retrieve individual newspaper pages via a website written in Java They have scanned the old newspapers into JPEGs (approx 17TB) and used Optical Character Recognition (OCR) to populate a commercial search product. The hosting platform and software are now end of life and the organization wants to migrate Its archive to AWS and produce a cost efficient architecture and still be designed for availability and durability Which is the most appropriate?</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="False">Use S3 with reduced redundancy lo store and serve the scanned files, install the commercial search application on EC2 Instances and configure with auto-scaling and an Elastic Load Balancer.</choice>
      <choice correct="True">Model the environment using CloudFormation use an EC2 instance running Apache webserver and an open source search application, stripe multiple standard EBS volumes together to store the JPEGs and search index.</choice>
      <choice correct="False">Use S3 with standard redundancy to store and serve the scanned files, use CloudSearch for query processing, and use Elastic Beanstalk to host the website across multiple availability zones.</choice>
      <choice correct="False">Use a single-AZ RDS MySQL instance lo store the search index 33d the JPEG images use an EC2 instance to serve the website and translate user queries into SQL.</choice>
      <choice correct="False">Use a CloudFront download distribution to serve the JPEGs to the end users and Install the current commercial search product, along with a Java Container Tor the website on EC2 instances and use Route53 with DNS round-robin.</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>A benefits enrollment company is hosting a 3-tier web application running in a VPC on AWS which includes a NAT (Network Address Translation) instance in the public Web tier. There is enough provisioned capacity for the expected workload tor the new fiscal year benefit enrollment period plus some extra overhead Enrollment proceeds nicely for two days and then the web tier becomes unresponsive, upon investigation using CloudWatch and other monitoring tools it is discovered that there is an extremely large and unanticipated amount of inbound traffic coming from a set of 15 specific IP addresses over port 80 from a country where the benefits company has no customers. The web tier instances are so overloaded that benefit enrollment administrators cannot even SSH into them. Which activity would be useful in defending against this attack?</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="True">Create a custom route table associated with the web tier and block the attacking IP addresses from the IGW (internet Gateway)</choice>
      <choice correct="False">Change the EIP (Elastic IP Address) of the NAT instance in the web tier subnet and update the Main Route Table with the new EIP</choice>
      <choice correct="False">Create 15 Security Group rules to block the attacking IP addresses over port 80</choice>
      <choice correct="False">Create an inbound NACL (Network Access control list) associated with the web tier subnet with deny rules to block the attacking IP addresses</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>An AWS customer runs a public blogging website. The site users upload two million blog entries a month The average blog entry size is 200 KB. The access rate to blog entries drops to negligible 6 months after publication and users rarely access a blog entry 1 year after publication. Additionally, blog entries have a high update rate during the first 3 months following publication, this drops to no updates after 6 months. The customer wants to use CloudFront to improve his user’s load times. Which of the following recommendations would you make to the customer?</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="False">Duplicate entries into two different buckets and create two separate CloudFront distributions where S3 access is restricted only to Cloud Front identity</choice>
      <choice correct="False">Create a CloudFront distribution with “US’Europe price class for US/Europe users and a different CloudFront distribution with All Edge Locations’ for the remaining users.</choice>
      <choice correct="True">Create a CloudFront distribution with S3 access restricted only to the CloudFront identity and partition the blog entry’s location in S3 according to the month it was uploaded to be used with CloudFront behaviors.</choice>
      <choice correct="False">Create a CloudFronl distribution with Restrict Viewer Access Forward Query string set to true and minimum TTL of 0.</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
<problem>
  <p>You require the ability to analyze a large amount of data, which is stored on Amazon S3 using Amazon Elastic Map Reduce. You are using the cc2 8x large Instance type, whose CPUs are mostly idle during processing. Which of the below would be the most cost efficient way to reduce the runtime of the job?</p>
  <multiplechoiceresponse>
    <choicegroup type="MultipleChoice" shuffle="True">
      <choice correct="False">Create more smaller flies on Amazon S3.</choice>
      <choice correct="False">Add additional cc2 8x large instances by introducing a task group.</choice>
      <choice correct="True">Use smaller instances that have higher aggregate I/O performance.</choice>
      <choice correct="False">Create fewer, larger files on Amazon S3.</choice>
    </choicegroup>
  </multiplechoiceresponse>
</problem>
